{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Train a Quadcopter How to Fly\n",
    "\n",
    "Design an agent to fly a quadcopter, and then train it using a reinforcement learning algorithm of your choice! \n",
    "\n",
    "Try to apply the techniques you have learnt, but also feel free to come up with innovative ideas and test them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Take a look at the files in the directory to better understand the structure of the project. \n",
    "\n",
    "- `task.py`: Define your task (environment) in this file.\n",
    "- `agents/`: Folder containing reinforcement learning agents.\n",
    "    - `policy_search.py`: A sample agent has been provided here.\n",
    "    - `agent.py`: Develop your agent here.\n",
    "- `physics_sim.py`: This file contains the simulator for the quadcopter.  **DO NOT MODIFY THIS FILE**.\n",
    "\n",
    "For this project, you will define your own task in `task.py`.  Although we have provided a example task to get you started, you are encouraged to change it.  Later in this notebook, you will learn more about how to amend this file.\n",
    "\n",
    "You will also design a reinforcement learning agent in `agent.py` to complete your chosen task.  \n",
    "\n",
    "You are welcome to create any additional files to help you to organize your code.  For instance, you may find it useful to define a `model.py` file defining any needed neural network architectures.\n",
    "\n",
    "## Controlling the Quadcopter\n",
    "\n",
    "We provide a sample agent in the code cell below to show you how to use the sim to control the quadcopter.  This agent is even simpler than the sample agent that you'll examine (in `agents/policy_search.py`) later in this notebook!\n",
    "\n",
    "The agent controls the quadcopter by setting the revolutions per second on each of its four rotors.  The provided agent in the `Basic_Agent` class below always selects a random action for each of the four rotors.  These four speeds are returned by the `act` method as a list of four floating-point numbers.  \n",
    "\n",
    "For this project, the agent that you will implement in `agents/agent.py` will have a far more intelligent method for selecting actions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Basic_Agent():\n",
    "    def __init__(self, task):\n",
    "        self.task = task\n",
    "    \n",
    "    def act(self):\n",
    "        new_thrust = random.gauss(450., 25.)\n",
    "        return [new_thrust + random.gauss(0., 1.) for x in range(4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to have the agent select actions to control the quadcopter.  \n",
    "\n",
    "Feel free to change the provided values of `runtime`, `init_pose`, `init_velocities`, and `init_angle_velocities` below to change the starting conditions of the quadcopter.\n",
    "\n",
    "The `labels` list below annotates statistics that are saved while running the simulation.  All of this information is saved in a text file `data.txt` and stored in the dictionary `results`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "from task import Task\n",
    "\n",
    "# Modify the values below to give the quadcopter a different starting position.\n",
    "runtime = 5.                                     # time limit of the episode\n",
    "init_pose = np.array([0., 0., 10., 0., 0., 0.])  # initial pose\n",
    "init_velocities = np.array([0., 0., 0.])         # initial velocities\n",
    "init_angle_velocities = np.array([0., 0., 0.])   # initial angle velocities\n",
    "file_output = 'data.txt'                         # file name for saved results\n",
    "\n",
    "# Setup\n",
    "task = Task(init_pose, init_velocities, init_angle_velocities, runtime)\n",
    "agent = Basic_Agent(task)\n",
    "done = False\n",
    "labels = ['time', 'x', 'y', 'z', 'phi', 'theta', 'psi', 'x_velocity',\n",
    "          'y_velocity', 'z_velocity', 'phi_velocity', 'theta_velocity',\n",
    "          'psi_velocity', 'rotor_speed1', 'rotor_speed2', 'rotor_speed3', 'rotor_speed4']\n",
    "results = {x : [] for x in labels}\n",
    "\n",
    "# Run the simulation, and save the results.\n",
    "with open(file_output, 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(labels)\n",
    "    while True:\n",
    "        rotor_speeds = agent.act()\n",
    "        _, _, done = task.step(rotor_speeds)\n",
    "        to_write = [task.sim.time] + list(task.sim.pose) + list(task.sim.v) + list(task.sim.angular_v) + list(rotor_speeds)\n",
    "        for ii in range(len(labels)):\n",
    "            results[labels[ii]].append(to_write[ii])\n",
    "        writer.writerow(to_write)\n",
    "        if done:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to visualize how the position of the quadcopter evolved during the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(results['time'], results['x'], label='x')\n",
    "plt.plot(results['time'], results['y'], label='y')\n",
    "plt.plot(results['time'], results['z'], label='z')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code cell visualizes the velocity of the quadcopter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results['time'], results['x_velocity'], label='x_hat')\n",
    "plt.plot(results['time'], results['y_velocity'], label='y_hat')\n",
    "plt.plot(results['time'], results['z_velocity'], label='z_hat')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you can plot the Euler angles (the rotation of the quadcopter over the $x$-, $y$-, and $z$-axes),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results['time'], results['phi'], label='phi')\n",
    "plt.plot(results['time'], results['theta'], label='theta')\n",
    "plt.plot(results['time'], results['psi'], label='psi')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before plotting the velocities (in radians per second) corresponding to each of the Euler angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results['time'], results['phi_velocity'], label='phi_velocity')\n",
    "plt.plot(results['time'], results['theta_velocity'], label='theta_velocity')\n",
    "plt.plot(results['time'], results['psi_velocity'], label='psi_velocity')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can use the code cell below to print the agent's choice of actions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results['time'], results['rotor_speed1'], label='Rotor 1 revolutions / second')\n",
    "plt.plot(results['time'], results['rotor_speed2'], label='Rotor 2 revolutions / second')\n",
    "plt.plot(results['time'], results['rotor_speed3'], label='Rotor 3 revolutions / second')\n",
    "plt.plot(results['time'], results['rotor_speed4'], label='Rotor 4 revolutions / second')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When specifying a task, you will derive the environment state from the simulator.  Run the code cell below to print the values of the following variables at the end of the simulation:\n",
    "- `task.sim.pose` (the position of the quadcopter in ($x,y,z$) dimensions and the Euler angles),\n",
    "- `task.sim.v` (the velocity of the quadcopter in ($x,y,z$) dimensions), and\n",
    "- `task.sim.angular_v` (radians/second for each of the three Euler angles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pose, velocity, and angular velocity of the quadcopter at the end of the episode\n",
    "print(task.sim.pose)\n",
    "print(task.sim.v)\n",
    "print(task.sim.angular_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the sample task in `task.py`, we use the 6-dimensional pose of the quadcopter to construct the state of the environment at each timestep.  However, when amending the task for your purposes, you are welcome to expand the size of the state vector by including the velocity information.  You can use any combination of the pose, velocity, and angular velocity - feel free to tinker here, and construct the state to suit your task.\n",
    "\n",
    "## The Task\n",
    "\n",
    "A sample task has been provided for you in `task.py`.  Open this file in a new window now. \n",
    "\n",
    "The `__init__()` method is used to initialize several variables that are needed to specify the task.  \n",
    "- The simulator is initialized as an instance of the `PhysicsSim` class (from `physics_sim.py`).  \n",
    "- Inspired by the methodology in the original DDPG paper, we make use of action repeats.  For each timestep of the agent, we step the simulation `action_repeats` timesteps.  If you are not familiar with action repeats, please read the **Results** section in [the DDPG paper](https://arxiv.org/abs/1509.02971).\n",
    "- We set the number of elements in the state vector.  For the sample task, we only work with the 6-dimensional pose information.  To set the size of the state (`state_size`), we must take action repeats into account.  \n",
    "- The environment will always have a 4-dimensional action space, with one entry for each rotor (`action_size=4`). You can set the minimum (`action_low`) and maximum (`action_high`) values of each entry here.\n",
    "- The sample task in this provided file is for the agent to reach a target position.  We specify that target position as a variable.\n",
    "\n",
    "The `reset()` method resets the simulator.  The agent should call this method every time the episode ends.  You can see an example of this in the code cell below.\n",
    "\n",
    "The `step()` method is perhaps the most important.  It accepts the agent's choice of action `rotor_speeds`, which is used to prepare the next state to pass on to the agent.  Then, the reward is computed from `get_reward()`.  The episode is considered done if the time limit has been exceeded, or the quadcopter has travelled outside of the bounds of the simulation.\n",
    "\n",
    "In the next section, you will learn how to test the performance of an agent on this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Agent\n",
    "\n",
    "The sample agent given in `agents/policy_search.py` uses a very simplistic linear policy to directly compute the action vector as a dot product of the state vector and a matrix of weights. Then, it randomly perturbs the parameters by adding some Gaussian noise, to produce a different policy. Based on the average reward obtained in each episode (`score`), it keeps track of the best set of parameters found so far, how the score is changing, and accordingly tweaks a scaling factor to widen or tighten the noise.\n",
    "\n",
    "Run the code cell below to see how the agent performs on the sample task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from agents.policy_search import PolicySearch_Agent\n",
    "from task import Task\n",
    "\n",
    "num_episodes = 1000\n",
    "init_pos = np.array([0., 0., 1.])\n",
    "target_pos = np.array([0., 0., 10.])\n",
    "task = Task(target_pos=target_pos)\n",
    "agent = PolicySearch_Agent(task) \n",
    "\n",
    "for i_episode in range(1, num_episodes+1):\n",
    "    state = agent.reset_episode() # start a new episode\n",
    "    while True:\n",
    "        action = agent.act(state) \n",
    "        next_state, reward, done = task.step(action)\n",
    "        agent.step(reward, done)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(\"\\rEpisode = {:4d}, score = {:7.3f} (best = {:7.3f}), noise_scale = {}\".format(\n",
    "                i_episode, agent.score, agent.best_score, agent.noise_scale), end=\"\")  # [debug]\n",
    "            break\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This agent should perform very poorly on this task.  And that's where you come in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Define the Task, Design the Agent, and Train Your Agent!\n",
    "\n",
    "Amend `task.py` to specify a task of your choosing.  If you're unsure what kind of task to specify, you may like to teach your quadcopter to takeoff, hover in place, land softly, or reach a target pose.  \n",
    "\n",
    "After specifying your task, use the sample agent in `agents/policy_search.py` as a template to define your own agent in `agents/agent.py`.  You can borrow whatever you need from the sample agent, including ideas on how you might modularize your code (using helper methods like `act()`, `learn()`, `reset_episode()`, etc.).\n",
    "\n",
    "Note that it is **highly unlikely** that the first agent and task that you specify will learn well.  You will likely have to tweak various hyperparameters and the reward function for your task until you arrive at reasonably good behavior.\n",
    "\n",
    "As you develop your agent, it's important to keep an eye on how it's performing. Use the code above as inspiration to build in a mechanism to log/save the total rewards obtained in each episode to file.  If the episode rewards are gradually increasing, this is an indication that your agent is learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "episode:   1, sum:-983.008, avg: -15.123, closest:  0.997, final x, y, z:[ -3.732,  -2.901,   0.000], steps:  65\n",
      "episode:   2, sum:-1981.439, avg: -22.263, closest:  0.998, final x, y, z:[ -2.198,   1.060,   0.000], steps:  89\n",
      "episode:   3, sum:-978.987, avg: -13.411, closest:  0.997, final x, y, z:[ -0.154,   1.894,   0.000], steps:  73\n",
      "episode:   4, sum:-982.003, avg: -14.441, closest:  0.994, final x, y, z:[ -2.800,   1.039,   0.000], steps:  68\n",
      "episode:   5, sum:-978.178, avg: -13.042, closest:  0.988, final x, y, z:[ -3.877,   3.140,   0.000], steps:  75\n",
      "episode:   6, sum:-980.716, avg: -13.813, closest:  0.996, final x, y, z:[ -4.866,  -2.977,   0.000], steps:  71\n",
      "episode:   7, sum:-1976.850, avg: -26.011, closest:  0.877, final x, y, z:[  3.623,   4.451,   0.000], steps:  76\n",
      "episode:   8, sum:-1979.490, avg: -26.046, closest:  0.927, final x, y, z:[-11.995,   0.968,   0.000], steps:  76\n",
      "episode:   9, sum:-975.094, avg: -12.343, closest:  0.804, final x, y, z:[-18.672,   4.870,   0.000], steps:  79\n",
      "episode:  10, sum:-978.419, avg: -11.511, closest:  0.834, final x, y, z:[-26.121,   4.088,   0.000], steps:  85\n",
      "episode:  11, sum:-970.623, avg: -11.555, closest:  0.782, final x, y, z:[  0.349,   6.443,   0.000], steps:  84\n",
      "episode:  12, sum:-970.752, avg: -11.557, closest:  0.782, final x, y, z:[  0.798,   6.481,   0.000], steps:  84\n",
      "episode:  13, sum:-971.233, avg: -11.702, closest:  0.785, final x, y, z:[  0.717,   6.415,   0.000], steps:  83\n",
      "episode:  14, sum:-971.583, avg: -11.706, closest:  0.788, final x, y, z:[ -2.477,   6.440,   0.000], steps:  83\n",
      "episode:  15, sum:-971.182, avg: -11.701, closest:  0.784, final x, y, z:[ -0.828,   6.403,   0.000], steps:  83\n",
      "episode:  16, sum:-1971.105, avg: -23.466, closest:  0.785, final x, y, z:[  0.366,   6.490,   0.000], steps:  84\n",
      "episode:  17, sum:-971.231, avg: -11.702, closest:  0.784, final x, y, z:[ -0.814,   6.391,   0.000], steps:  83\n",
      "episode:  18, sum:-971.514, avg:  -9.619, closest:  0.788, final x, y, z:[  0.496,   7.281,   0.000], steps: 101\n",
      "episode:  19, sum:2067.281, avg: 103.364, closest:  0.033, final x, y, z:[  0.002,  -0.000,  10.033], steps:  20\n",
      "episode:  20, sum:1956.249, avg:  97.812, closest:  0.035, final x, y, z:[ -0.001,  -0.000,  10.035], steps:  20\n",
      "episode:  21, sum:1999.632, avg:  99.982, closest:  0.034, final x, y, z:[  0.003,   0.000,  10.034], steps:  20\n",
      "episode:  22, sum:2073.848, avg: 103.692, closest:  0.033, final x, y, z:[ -0.001,   0.000,  10.033], steps:  20\n",
      "episode:  23, sum:2062.247, avg: 103.112, closest:  0.034, final x, y, z:[ -0.002,  -0.000,  10.033], steps:  20\n",
      "episode:  24, sum:2043.695, avg: 102.185, closest:  0.034, final x, y, z:[ -0.001,  -0.000,  10.034], steps:  20\n",
      "episode:  25, sum:2021.737, avg: 101.087, closest:  0.034, final x, y, z:[ -0.004,  -0.000,  10.034], steps:  20\n",
      "episode:  26, sum:2054.414, avg: 102.721, closest:  0.034, final x, y, z:[  0.002,   0.000,  10.034], steps:  20\n",
      "episode:  27, sum:2003.625, avg: 100.181, closest:  0.034, final x, y, z:[  0.002,   0.000,  10.034], steps:  20\n",
      "episode:  28, sum:2057.492, avg: 102.875, closest:  0.034, final x, y, z:[ -0.000,   0.000,  10.034], steps:  20\n",
      "episode:  29, sum:2029.787, avg: 101.489, closest:  0.034, final x, y, z:[ -0.000,  -0.000,  10.034], steps:  20\n",
      "episode:  30, sum:2080.420, avg: 104.021, closest:  0.033, final x, y, z:[ -0.000,  -0.000,  10.033], steps:  20\n",
      "episode:  31, sum:2065.891, avg: 103.295, closest:  0.033, final x, y, z:[ -0.001,   0.000,  10.033], steps:  20\n",
      "episode:  32, sum:1957.724, avg:  97.886, closest:  0.035, final x, y, z:[  0.001,  -0.000,  10.035], steps:  20\n",
      "episode:  33, sum:2005.005, avg: 100.250, closest:  0.034, final x, y, z:[ -0.000,  -0.000,  10.034], steps:  20\n",
      "episode:  34, sum:2002.786, avg: 100.139, closest:  0.034, final x, y, z:[  0.001,  -0.000,  10.034], steps:  20\n",
      "episode:  35, sum:2007.497, avg: 100.375, closest:  0.034, final x, y, z:[  0.004,  -0.000,  10.034], steps:  20\n",
      "episode:  36, sum:1983.585, avg:  99.179, closest:  0.034, final x, y, z:[  0.002,   0.000,  10.034], steps:  20\n",
      "episode:  37, sum:2044.153, avg: 102.208, closest:  0.034, final x, y, z:[  0.002,   0.000,  10.034], steps:  20\n",
      "episode:  38, sum:1953.523, avg:  97.676, closest:  0.035, final x, y, z:[  0.001,  -0.000,  10.035], steps:  20\n",
      "episode:  39, sum:2003.473, avg: 100.174, closest:  0.034, final x, y, z:[ -0.003,  -0.000,  10.034], steps:  20\n",
      "episode:  40, sum:2052.142, avg: 102.607, closest:  0.034, final x, y, z:[  0.003,  -0.000,  10.033], steps:  20\n",
      "episode:  41, sum:1989.128, avg:  99.456, closest:  0.034, final x, y, z:[ -0.001,  -0.000,  10.034], steps:  20\n",
      "episode:  42, sum:2089.122, avg: 104.456, closest:  0.033, final x, y, z:[ -0.003,   0.000,  10.033], steps:  20\n",
      "episode:  43, sum:2090.030, avg: 104.501, closest:  0.033, final x, y, z:[  0.000,  -0.000,  10.033], steps:  20\n",
      "episode:  44, sum:1951.318, avg:  97.566, closest:  0.035, final x, y, z:[ -0.005,  -0.000,  10.034], steps:  20\n",
      "episode:  45, sum:2137.145, avg: 106.857, closest:  0.033, final x, y, z:[  0.001,   0.000,  10.033], steps:  20\n",
      "episode:  46, sum:1941.410, avg:  97.071, closest:  0.035, final x, y, z:[ -0.000,   0.000,  10.035], steps:  20\n",
      "episode:  47, sum:2043.395, avg: 102.170, closest:  0.034, final x, y, z:[  0.004,   0.000,  10.033], steps:  20\n",
      "episode:  48, sum:1998.918, avg:  99.946, closest:  0.034, final x, y, z:[ -0.001,   0.000,  10.034], steps:  20\n",
      "episode:  49, sum:2032.340, avg: 101.617, closest:  0.034, final x, y, z:[ -0.000,   0.000,  10.034], steps:  20\n",
      "episode:  50, sum:2119.705, avg: 105.985, closest:  0.033, final x, y, z:[  0.003,  -0.000,  10.033], steps:  20\n",
      "episode:  51, sum:1938.371, avg:  96.919, closest:  0.035, final x, y, z:[  0.002,  -0.000,  10.035], steps:  20\n",
      "episode:  52, sum:2005.210, avg: 100.260, closest:  0.034, final x, y, z:[ -0.003,   0.000,  10.034], steps:  20\n",
      "episode:  53, sum:1950.108, avg:  97.505, closest:  0.035, final x, y, z:[  0.002,  -0.000,  10.035], steps:  20\n",
      "episode:  54, sum:2139.749, avg: 106.987, closest:  0.033, final x, y, z:[  0.002,   0.000,  10.033], steps:  20\n",
      "episode:  55, sum:1947.841, avg:  97.392, closest:  0.035, final x, y, z:[ -0.002,  -0.000,  10.035], steps:  20\n",
      "episode:  56, sum:2077.719, avg: 103.886, closest:  0.033, final x, y, z:[  0.001,   0.000,  10.033], steps:  20\n",
      "episode:  57, sum:1927.790, avg:  96.390, closest:  0.035, final x, y, z:[ -0.003,  -0.000,  10.035], steps:  20\n",
      "episode:  58, sum:2077.229, avg: 103.861, closest:  0.033, final x, y, z:[ -0.004,   0.000,  10.033], steps:  20\n",
      "episode:  59, sum:2057.590, avg: 102.879, closest:  0.034, final x, y, z:[ -0.001,  -0.000,  10.034], steps:  20\n",
      "episode:  60, sum:1984.370, avg:  99.218, closest:  0.034, final x, y, z:[ -0.003,   0.000,  10.034], steps:  20\n",
      "episode:  61, sum:2003.317, avg: 100.166, closest:  0.034, final x, y, z:[ -0.002,  -0.000,  10.034], steps:  20\n",
      "episode:  62, sum:1910.800, avg:  95.540, closest:  0.035, final x, y, z:[  0.001,   0.000,  10.035], steps:  20\n",
      "episode:  63, sum:1932.947, avg:  96.647, closest:  0.035, final x, y, z:[  0.001,   0.000,  10.035], steps:  20\n",
      "episode:  64, sum:2019.662, avg: 100.983, closest:  0.034, final x, y, z:[  0.002,  -0.000,  10.034], steps:  20\n",
      "episode:  65, sum:2067.919, avg: 103.396, closest:  0.033, final x, y, z:[ -0.000,   0.000,  10.033], steps:  20\n",
      "episode:  66, sum:2050.279, avg: 102.514, closest:  0.034, final x, y, z:[  0.003,   0.000,  10.034], steps:  20\n",
      "episode:  67, sum:2028.828, avg: 101.441, closest:  0.034, final x, y, z:[  0.002,   0.000,  10.034], steps:  20\n",
      "episode:  68, sum:1958.970, avg:  97.948, closest:  0.035, final x, y, z:[  0.003,  -0.000,  10.034], steps:  20\n",
      "episode:  69, sum:1937.598, avg:  96.880, closest:  0.035, final x, y, z:[  0.003,  -0.000,  10.035], steps:  20\n",
      "episode:  70, sum:2039.353, avg: 101.968, closest:  0.034, final x, y, z:[ -0.001,   0.000,  10.034], steps:  20\n",
      "episode:  71, sum:2018.233, avg: 100.912, closest:  0.034, final x, y, z:[ -0.005,  -0.000,  10.034], steps:  20\n",
      "episode:  72, sum:2111.736, avg: 105.587, closest:  0.033, final x, y, z:[ -0.001,   0.000,  10.033], steps:  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  73, sum:2083.935, avg: 104.197, closest:  0.033, final x, y, z:[  0.001,   0.000,  10.033], steps:  20\n",
      "episode:  74, sum:1963.777, avg:  98.189, closest:  0.035, final x, y, z:[ -0.000,   0.000,  10.035], steps:  20\n",
      "episode:  75, sum:2047.950, avg: 102.398, closest:  0.034, final x, y, z:[ -0.001,  -0.000,  10.034], steps:  20\n",
      "episode:  76, sum:2057.465, avg: 102.873, closest:  0.034, final x, y, z:[  0.004,   0.000,  10.033], steps:  20\n",
      "episode:  77, sum:2155.739, avg: 107.787, closest:  0.033, final x, y, z:[  0.000,   0.000,  10.033], steps:  20\n",
      "episode:  78, sum:2049.023, avg: 102.451, closest:  0.034, final x, y, z:[ -0.001,  -0.000,  10.034], steps:  20\n",
      "episode:  79, sum:2117.610, avg: 105.881, closest:  0.033, final x, y, z:[ -0.002,  -0.000,  10.033], steps:  20\n",
      "episode:  80, sum:1968.382, avg:  98.419, closest:  0.035, final x, y, z:[ -0.003,  -0.000,  10.034], steps:  20\n",
      "episode:  81, sum:2014.522, avg: 100.726, closest:  0.034, final x, y, z:[  0.001,  -0.000,  10.034], steps:  20\n",
      "episode:  82, sum:2038.710, avg: 101.936, closest:  0.034, final x, y, z:[ -0.002,  -0.000,  10.034], steps:  20\n",
      "episode:  83, sum:2043.586, avg: 102.179, closest:  0.034, final x, y, z:[  0.001,  -0.000,  10.034], steps:  20\n",
      "episode:  84, sum:1979.763, avg:  98.988, closest:  0.034, final x, y, z:[ -0.002,  -0.000,  10.034], steps:  20\n",
      "episode:  85, sum:2121.241, avg: 106.062, closest:  0.033, final x, y, z:[ -0.001,  -0.000,  10.033], steps:  20\n",
      "episode:  86, sum:2100.610, avg: 105.031, closest:  0.033, final x, y, z:[  0.001,  -0.000,  10.033], steps:  20\n",
      "episode:  87, sum:2031.122, avg: 101.556, closest:  0.034, final x, y, z:[ -0.003,   0.000,  10.034], steps:  20\n",
      "episode:  88, sum:1964.699, avg:  98.235, closest:  0.035, final x, y, z:[ -0.003,   0.000,  10.034], steps:  20\n",
      "episode:  89, sum:1904.470, avg:  95.223, closest:  0.035, final x, y, z:[  0.003,   0.000,  10.035], steps:  20\n",
      "episode:  90, sum:1988.646, avg:  99.432, closest:  0.034, final x, y, z:[ -0.001,  -0.000,  10.034], steps:  20\n",
      "episode:  91, sum:1945.750, avg:  97.287, closest:  0.035, final x, y, z:[  0.002,   0.000,  10.035], steps:  20\n",
      "episode:  92, sum:2175.429, avg: 108.771, closest:  0.032, final x, y, z:[ -0.001,  -0.000,  10.032], steps:  20\n",
      "episode:  93, sum:2054.862, avg: 102.743, closest:  0.034, final x, y, z:[  0.001,   0.000,  10.034], steps:  20\n",
      "episode:  94, sum:1928.513, avg:  96.426, closest:  0.035, final x, y, z:[ -0.002,  -0.000,  10.035], steps:  20\n",
      "episode:  95, sum:2043.536, avg: 102.177, closest:  0.034, final x, y, z:[  0.001,  -0.000,  10.034], steps:  20\n",
      "episode:  96, sum:1992.617, avg:  99.631, closest:  0.034, final x, y, z:[  0.002,  -0.000,  10.034], steps:  20\n",
      "episode:  97, sum:2130.022, avg: 106.501, closest:  0.033, final x, y, z:[ -0.001,  -0.000,  10.033], steps:  20\n",
      "episode:  98, sum:2023.950, avg: 101.198, closest:  0.034, final x, y, z:[  0.003,  -0.000,  10.034], steps:  20\n",
      "episode:  99, sum:2013.030, avg: 100.652, closest:  0.034, final x, y, z:[  0.001,   0.000,  10.034], steps:  20\n",
      "episode: 100, sum:2085.346, avg: 104.267, closest:  0.033, final x, y, z:[  0.001,  -0.000,  10.033], steps:  20\n",
      "episode: 101, sum:2057.005, avg: 102.850, closest:  0.034, final x, y, z:[ -0.001,  -0.000,  10.034], steps:  20\n",
      "episode: 102, sum:2022.774, avg: 101.139, closest:  0.034, final x, y, z:[ -0.001,   0.000,  10.034], steps:  20\n",
      "episode: 103, sum:1986.887, avg:  99.344, closest:  0.034, final x, y, z:[  0.002,  -0.000,  10.034], steps:  20\n",
      "episode: 104, sum:1960.841, avg:  98.042, closest:  0.035, final x, y, z:[  0.002,  -0.000,  10.035], steps:  20\n",
      "episode: 105, sum:1986.452, avg:  99.323, closest:  0.034, final x, y, z:[ -0.002,   0.000,  10.034], steps:  20\n",
      "episode: 106, sum:2041.122, avg: 102.056, closest:  0.034, final x, y, z:[  0.000,  -0.000,  10.034], steps:  20\n",
      "episode: 107, sum:1889.466, avg:  94.473, closest:  0.035, final x, y, z:[ -0.004,  -0.000,  10.035], steps:  20\n",
      "episode: 108, sum:2158.705, avg: 107.935, closest:  0.033, final x, y, z:[  0.000,  -0.000,  10.033], steps:  20\n",
      "episode: 109, sum:2015.985, avg: 100.799, closest:  0.034, final x, y, z:[ -0.002,   0.000,  10.034], steps:  20\n",
      "episode: 110, sum:1989.208, avg:  99.460, closest:  0.034, final x, y, z:[ -0.004,   0.000,  10.034], steps:  20\n",
      "episode: 111, sum:2042.400, avg: 102.120, closest:  0.034, final x, y, z:[ -0.002,  -0.000,  10.034], steps:  20\n",
      "episode: 112, sum:1992.581, avg:  99.629, closest:  0.034, final x, y, z:[ -0.001,  -0.000,  10.034], steps:  20\n",
      "episode: 113, sum:2006.713, avg: 100.336, closest:  0.034, final x, y, z:[ -0.002,  -0.000,  10.034], steps:  20\n",
      "episode: 114, sum:2000.924, avg: 100.046, closest:  0.034, final x, y, z:[  0.001,   0.000,  10.034], steps:  20\n",
      "episode: 115, sum:2064.129, avg: 103.206, closest:  0.034, final x, y, z:[ -0.002,   0.000,  10.033], steps:  20\n",
      "episode: 116, sum:2056.239, avg: 102.812, closest:  0.034, final x, y, z:[  0.001,   0.000,  10.034], steps:  20\n",
      "episode: 117, sum:2047.351, avg: 102.368, closest:  0.034, final x, y, z:[  0.001,   0.000,  10.034], steps:  20\n",
      "episode: 118, sum:1986.954, avg:  99.348, closest:  0.034, final x, y, z:[ -0.002,  -0.000,  10.034], steps:  20\n",
      "episode: 119, sum:1972.383, avg:  98.619, closest:  0.034, final x, y, z:[  0.000,  -0.000,  10.034], steps:  20\n",
      "episode: 120, sum:2005.470, avg: 100.274, closest:  0.034, final x, y, z:[  0.001,   0.000,  10.034], steps:  20\n",
      "episode: 121, sum:1942.294, avg:  97.115, closest:  0.035, final x, y, z:[  0.001,  -0.000,  10.035], steps:  20\n",
      "episode: 122, sum:2116.563, avg: 105.828, closest:  0.033, final x, y, z:[ -0.001,  -0.000,  10.033], steps:  20\n",
      "episode: 123, sum:1891.603, avg:  94.580, closest:  0.035, final x, y, z:[  0.000,   0.000,  10.035], steps:  20\n",
      "episode: 124, sum:2036.210, avg: 101.811, closest:  0.034, final x, y, z:[  0.001,  -0.000,  10.034], steps:  20\n",
      "episode: 125, sum:1899.948, avg:  94.997, closest:  0.035, final x, y, z:[  0.004,   0.000,  10.035], steps:  20\n",
      "episode: 126, sum:2016.438, avg: 100.822, closest:  0.034, final x, y, z:[ -0.003,  -0.000,  10.034], steps:  20\n",
      "episode: 127, sum:2006.409, avg: 100.320, closest:  0.034, final x, y, z:[ -0.000,   0.000,  10.034], steps:  20\n",
      "episode: 128, sum:1957.172, avg:  97.859, closest:  0.035, final x, y, z:[  0.001,   0.000,  10.035], steps:  20\n",
      "episode: 129, sum:2042.356, avg: 102.118, closest:  0.034, final x, y, z:[  0.000,   0.000,  10.034], steps:  20\n",
      "episode: 130, sum:2037.611, avg: 101.881, closest:  0.034, final x, y, z:[  0.001,  -0.000,  10.034], steps:  20\n",
      "episode: 131, sum:2033.051, avg: 101.653, closest:  0.034, final x, y, z:[ -0.002,   0.000,  10.034], steps:  20\n",
      "episode: 132, sum:2004.445, avg: 100.222, closest:  0.034, final x, y, z:[ -0.002,   0.000,  10.034], steps:  20\n",
      "episode: 133, sum:1983.847, avg:  99.192, closest:  0.034, final x, y, z:[  0.001,   0.000,  10.034], steps:  20\n",
      "episode: 134, sum:2033.814, avg: 101.691, closest:  0.034, final x, y, z:[  0.001,   0.000,  10.034], steps:  20\n",
      "episode: 135, sum:2112.611, avg: 105.631, closest:  0.033, final x, y, z:[  0.002,  -0.000,  10.033], steps:  20\n",
      "episode: 136, sum:1989.152, avg:  99.458, closest:  0.034, final x, y, z:[  0.004,  -0.000,  10.034], steps:  20\n",
      "episode: 137, sum:2092.712, avg: 104.636, closest:  0.033, final x, y, z:[ -0.001,  -0.000,  10.033], steps:  20\n",
      "episode: 138, sum:2143.655, avg: 107.183, closest:  0.033, final x, y, z:[ -0.003,  -0.000,  10.033], steps:  20\n",
      "episode: 139, sum:2075.159, avg: 103.758, closest:  0.033, final x, y, z:[  0.003,  -0.000,  10.033], steps:  20\n",
      "episode: 140, sum:1978.241, avg:  98.912, closest:  0.034, final x, y, z:[ -0.001,  -0.000,  10.034], steps:  20\n",
      "episode: 141, sum:1989.107, avg:  99.455, closest:  0.034, final x, y, z:[  0.000,  -0.000,  10.034], steps:  20\n",
      "episode: 142, sum:2140.873, avg: 107.044, closest:  0.033, final x, y, z:[  0.001,   0.000,  10.033], steps:  20\n",
      "episode: 143, sum:2134.099, avg: 106.705, closest:  0.033, final x, y, z:[ -0.002,  -0.000,  10.033], steps:  20\n",
      "episode: 144, sum:2035.502, avg: 101.775, closest:  0.034, final x, y, z:[ -0.002,  -0.000,  10.034], steps:  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 145, sum:1970.611, avg:  98.531, closest:  0.034, final x, y, z:[  0.003,   0.000,  10.034], steps:  20\n",
      "episode: 146, sum:1972.853, avg:  98.643, closest:  0.034, final x, y, z:[ -0.003,  -0.000,  10.034], steps:  20\n",
      "episode: 147, sum:2062.528, avg: 103.126, closest:  0.034, final x, y, z:[  0.004,   0.000,  10.033], steps:  20\n",
      "episode: 148, sum:2081.971, avg: 104.099, closest:  0.033, final x, y, z:[  0.001,  -0.000,  10.033], steps:  20\n",
      "episode: 149, sum:2102.381, avg: 105.119, closest:  0.033, final x, y, z:[  0.000,  -0.000,  10.033], steps:  20\n",
      "episode: 150, sum:2042.822, avg: 102.141, closest:  0.034, final x, y, z:[ -0.002,  -0.000,  10.034], steps:  20\n",
      "episode: 151, sum:2034.170, avg: 101.708, closest:  0.034, final x, y, z:[ -0.002,  -0.000,  10.034], steps:  20\n",
      "episode: 152, sum:2086.369, avg: 104.318, closest:  0.033, final x, y, z:[  0.003,  -0.000,  10.033], steps:  20\n",
      "episode: 153, sum:2136.440, avg: 106.822, closest:  0.033, final x, y, z:[  0.000,   0.000,  10.033], steps:  20\n",
      "episode: 154, sum:2033.150, avg: 101.657, closest:  0.034, final x, y, z:[ -0.001,   0.000,  10.034], steps:  20\n",
      "episode: 155, sum:2036.158, avg: 101.808, closest:  0.034, final x, y, z:[  0.002,   0.000,  10.034], steps:  20\n",
      "episode: 156, sum:1988.378, avg:  99.419, closest:  0.034, final x, y, z:[ -0.001,  -0.000,  10.034], steps:  20\n",
      "episode: 157, sum:2104.947, avg: 105.247, closest:  0.033, final x, y, z:[  0.000,   0.000,  10.033], steps:  20\n",
      "episode: 158, sum:2012.385, avg: 100.619, closest:  0.034, final x, y, z:[  0.004,  -0.000,  10.034], steps:  20\n",
      "episode: 159, sum:2004.639, avg: 100.232, closest:  0.034, final x, y, z:[ -0.001,   0.000,  10.034], steps:  20\n",
      "episode: 160, sum:1945.350, avg:  97.268, closest:  0.035, final x, y, z:[  0.000,  -0.000,  10.035], steps:  20\n",
      "episode: 161, sum:1956.774, avg:  97.839, closest:  0.035, final x, y, z:[ -0.000,  -0.000,  10.035], steps:  20\n",
      "episode: 162, sum:2000.546, avg: 100.027, closest:  0.034, final x, y, z:[  0.005,   0.000,  10.034], steps:  20\n",
      "episode: 163, sum:1946.732, avg:  97.337, closest:  0.035, final x, y, z:[ -0.005,  -0.000,  10.034], steps:  20\n",
      "episode: 164, sum:1953.719, avg:  97.686, closest:  0.035, final x, y, z:[  0.002,  -0.000,  10.035], steps:  20\n",
      "episode: 165, sum:2065.920, avg: 103.296, closest:  0.033, final x, y, z:[  0.001,   0.000,  10.033], steps:  20\n",
      "episode: 166, sum:2008.103, avg: 100.405, closest:  0.034, final x, y, z:[  0.001,   0.000,  10.034], steps:  20\n",
      "episode: 167, sum:1941.448, avg:  97.072, closest:  0.035, final x, y, z:[  0.001,  -0.000,  10.035], steps:  20\n",
      "episode: 168, sum:2046.736, avg: 102.337, closest:  0.034, final x, y, z:[  0.000,   0.000,  10.034], steps:  20\n",
      "episode: 169, sum:2009.947, avg: 100.497, closest:  0.034, final x, y, z:[  0.001,   0.000,  10.034], steps:  20\n",
      "episode: 170, sum:1974.931, avg:  98.747, closest:  0.034, final x, y, z:[  0.000,   0.000,  10.034], steps:  20\n",
      "episode: 171, sum:1969.831, avg:  98.492, closest:  0.034, final x, y, z:[  0.007,   0.000,  10.034], steps:  20\n",
      "episode: 172, sum:2049.696, avg: 102.485, closest:  0.034, final x, y, z:[ -0.002,  -0.000,  10.034], steps:  20\n",
      "episode: 173, sum:2124.745, avg: 106.237, closest:  0.033, final x, y, z:[  0.003,  -0.000,  10.033], steps:  20\n",
      "episode: 174, sum:1976.423, avg:  98.821, closest:  0.034, final x, y, z:[ -0.000,   0.000,  10.034], steps:  20\n",
      "episode: 175, sum:1941.706, avg:  97.085, closest:  0.035, final x, y, z:[  0.002,  -0.000,  10.035], steps:  20\n",
      "episode: 176, sum:2012.972, avg: 100.649, closest:  0.034, final x, y, z:[ -0.001,  -0.000,  10.034], steps:  20\n",
      "episode: 177, sum:1990.968, avg:  99.548, closest:  0.034, final x, y, z:[  0.000,  -0.000,  10.034], steps:  20\n",
      "episode: 178, sum:2071.856, avg: 103.593, closest:  0.033, final x, y, z:[ -0.003,  -0.000,  10.033], steps:  20\n",
      "episode: 179, sum:2031.655, avg: 101.583, closest:  0.034, final x, y, z:[  0.002,   0.000,  10.034], steps:  20\n",
      "episode: 180, sum:2181.040, avg: 109.052, closest:  0.032, final x, y, z:[  0.001,   0.000,  10.032], steps:  20\n",
      "episode: 181, sum:1968.020, avg:  98.401, closest:  0.035, final x, y, z:[  0.001,   0.000,  10.034], steps:  20\n",
      "episode: 182, sum:2047.570, avg: 102.378, closest:  0.034, final x, y, z:[  0.001,  -0.000,  10.034], steps:  20\n",
      "episode: 183, sum:2024.715, avg: 101.236, closest:  0.034, final x, y, z:[ -0.001,   0.000,  10.034], steps:  20\n",
      "episode: 184, sum:2049.045, avg: 102.452, closest:  0.034, final x, y, z:[  0.001,  -0.000,  10.034], steps:  20\n",
      "episode: 185, sum:1922.217, avg:  96.111, closest:  0.035, final x, y, z:[ -0.003,   0.000,  10.035], steps:  20\n",
      "episode: 186, sum:2013.429, avg: 100.671, closest:  0.034, final x, y, z:[ -0.002,  -0.000,  10.034], steps:  20\n",
      "episode: 187, sum:1992.142, avg:  99.607, closest:  0.034, final x, y, z:[  0.001,   0.000,  10.034], steps:  20\n",
      "episode: 188, sum:2060.477, avg: 103.024, closest:  0.034, final x, y, z:[  0.001,   0.000,  10.034], steps:  20\n",
      "episode: 189, sum:2039.236, avg: 101.962, closest:  0.034, final x, y, z:[  0.001,  -0.000,  10.034], steps:  20\n",
      "episode: 190, sum:1974.637, avg:  98.732, closest:  0.034, final x, y, z:[ -0.000,   0.000,  10.034], steps:  20\n",
      "episode: 191, sum:1938.439, avg:  96.922, closest:  0.035, final x, y, z:[  0.001,  -0.000,  10.035], steps:  20\n",
      "episode: 192, sum:1982.499, avg:  99.125, closest:  0.034, final x, y, z:[ -0.001,  -0.000,  10.034], steps:  20\n",
      "episode: 193, sum:2084.843, avg: 104.242, closest:  0.033, final x, y, z:[ -0.001,   0.000,  10.033], steps:  20\n",
      "episode: 194, sum:1993.073, avg:  99.654, closest:  0.034, final x, y, z:[ -0.003,  -0.000,  10.034], steps:  20\n",
      "episode: 195, sum:2033.856, avg: 101.693, closest:  0.034, final x, y, z:[  0.001,  -0.000,  10.034], steps:  20\n",
      "episode: 196, sum:2103.115, avg: 105.156, closest:  0.033, final x, y, z:[ -0.002,  -0.000,  10.033], steps:  20\n",
      "episode: 197, sum:2076.369, avg: 103.818, closest:  0.033, final x, y, z:[  0.000,  -0.000,  10.033], steps:  20\n",
      "episode: 198, sum:2007.271, avg: 100.364, closest:  0.034, final x, y, z:[  0.002,  -0.000,  10.034], steps:  20\n",
      "episode: 199, sum:2058.769, avg: 102.938, closest:  0.034, final x, y, z:[  0.001,   0.000,  10.034], steps:  20\n",
      "episode: 200, sum:1951.493, avg:  97.575, closest:  0.035, final x, y, z:[ -0.001,  -0.000,  10.035], steps:  20\n",
      "episode: 201, sum:2019.238, avg: 100.962, closest:  0.034, final x, y, z:[  0.000,   0.000,  10.034], steps:  20\n",
      "episode: 202, sum:1986.574, avg:  99.329, closest:  0.034, final x, y, z:[  0.000,  -0.000,  10.034], steps:  20\n",
      "episode: 203, sum:2022.217, avg: 101.111, closest:  0.034, final x, y, z:[ -0.002,   0.000,  10.034], steps:  20\n",
      "episode: 204, sum:1916.181, avg:  95.809, closest:  0.035, final x, y, z:[ -0.004,   0.000,  10.035], steps:  20\n",
      "episode: 205, sum:2052.456, avg: 102.623, closest:  0.034, final x, y, z:[  0.003,   0.000,  10.033], steps:  20\n",
      "episode: 206, sum:2035.049, avg: 101.752, closest:  0.034, final x, y, z:[  0.003,  -0.000,  10.034], steps:  20\n",
      "episode: 207, sum:2041.491, avg: 102.075, closest:  0.034, final x, y, z:[ -0.001,   0.000,  10.034], steps:  20\n",
      "episode: 208, sum:1980.971, avg:  99.049, closest:  0.034, final x, y, z:[ -0.000,  -0.000,  10.034], steps:  20\n",
      "episode: 209, sum:1945.351, avg:  97.268, closest:  0.035, final x, y, z:[  0.001,   0.000,  10.035], steps:  20\n",
      "episode: 210, sum:2035.185, avg: 101.759, closest:  0.034, final x, y, z:[  0.001,  -0.000,  10.034], steps:  20\n",
      "episode: 211, sum:1985.039, avg:  99.252, closest:  0.034, final x, y, z:[ -0.004,  -0.000,  10.034], steps:  20\n",
      "episode: 212, sum:1988.815, avg:  99.441, closest:  0.034, final x, y, z:[ -0.001,  -0.000,  10.034], steps:  20\n",
      "episode: 213, sum:1990.380, avg:  99.519, closest:  0.034, final x, y, z:[  0.001,   0.000,  10.034], steps:  20\n",
      "episode: 214, sum:1991.612, avg:  99.581, closest:  0.034, final x, y, z:[ -0.003,   0.000,  10.034], steps:  20\n",
      "episode: 215, sum:2074.945, avg: 103.747, closest:  0.033, final x, y, z:[ -0.001,   0.000,  10.033], steps:  20\n",
      "episode: 216, sum:2181.003, avg: 109.050, closest:  0.032, final x, y, z:[  0.001,  -0.000,  10.032], steps:  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 217, sum:2088.127, avg: 104.406, closest:  0.033, final x, y, z:[  0.001,  -0.000,  10.033], steps:  20\n",
      "episode: 218, sum:2014.848, avg: 100.742, closest:  0.034, final x, y, z:[  0.000,  -0.000,  10.034], steps:  20\n",
      "episode: 219, sum:2078.337, avg: 103.917, closest:  0.033, final x, y, z:[ -0.002,  -0.000,  10.033], steps:  20\n",
      "episode: 220, sum:2015.942, avg: 100.797, closest:  0.034, final x, y, z:[ -0.001,   0.000,  10.034], steps:  20\n",
      "episode: 221, sum:2054.943, avg: 102.747, closest:  0.034, final x, y, z:[ -0.003,   0.000,  10.033], steps:  20\n",
      "episode: 222, sum:1986.251, avg:  99.313, closest:  0.034, final x, y, z:[ -0.003,  -0.000,  10.034], steps:  20\n",
      "episode: 223, sum:2037.317, avg: 101.866, closest:  0.034, final x, y, z:[  0.001,  -0.000,  10.034], steps:  20\n",
      "episode: 224, sum:1999.374, avg:  99.969, closest:  0.034, final x, y, z:[  0.001,  -0.000,  10.034], steps:  20\n",
      "episode: 225, sum:1977.722, avg:  98.886, closest:  0.034, final x, y, z:[ -0.002,   0.000,  10.034], steps:  20\n",
      "episode: 226, sum:2155.074, avg: 107.754, closest:  0.033, final x, y, z:[ -0.002,   0.000,  10.033], steps:  20\n",
      "episode: 227, sum:1965.912, avg:  98.296, closest:  0.035, final x, y, z:[ -0.003,  -0.000,  10.034], steps:  20\n",
      "episode: 228, sum:1959.520, avg:  97.976, closest:  0.035, final x, y, z:[  0.001,  -0.000,  10.035], steps:  20\n",
      "episode: 229, sum:2006.062, avg: 100.303, closest:  0.034, final x, y, z:[  0.002,   0.000,  10.034], steps:  20\n",
      "episode: 230, sum:1948.548, avg:  97.427, closest:  0.035, final x, y, z:[  0.002,   0.000,  10.035], steps:  20\n",
      "episode: 231, sum:1905.276, avg:  95.264, closest:  0.035, final x, y, z:[ -0.003,   0.000,  10.035], steps:  20\n",
      "episode: 232, sum:2004.654, avg: 100.233, closest:  0.034, final x, y, z:[  0.000,   0.000,  10.034], steps:  20\n",
      "episode: 233, sum:1949.150, avg:  97.458, closest:  0.035, final x, y, z:[  0.002,  -0.000,  10.035], steps:  20\n",
      "episode: 234, sum:2075.640, avg: 103.782, closest:  0.033, final x, y, z:[  0.001,  -0.000,  10.033], steps:  20\n",
      "episode: 235, sum:2058.141, avg: 102.907, closest:  0.034, final x, y, z:[  0.002,   0.000,  10.034], steps:  20\n",
      "episode: 236, sum:1980.085, avg:  99.004, closest:  0.034, final x, y, z:[  0.000,  -0.000,  10.034], steps:  20\n",
      "episode: 237, sum:2070.962, avg: 103.548, closest:  0.033, final x, y, z:[  0.001,   0.000,  10.033], steps:  20\n",
      "episode: 238, sum:1906.697, avg:  95.335, closest:  0.035, final x, y, z:[  0.004,  -0.000,  10.035], steps:  20\n",
      "episode: 239, sum:1937.949, avg:  96.897, closest:  0.035, final x, y, z:[ -0.001,   0.000,  10.035], steps:  20\n",
      "episode: 240, sum:1990.201, avg:  99.510, closest:  0.034, final x, y, z:[  0.000,   0.000,  10.034], steps:  20\n",
      "episode: 241, sum:2021.515, avg: 101.076, closest:  0.034, final x, y, z:[  0.005,   0.000,  10.034], steps:  20\n",
      "episode: 242, sum:2016.855, avg: 100.843, closest:  0.034, final x, y, z:[ -0.002,  -0.000,  10.034], steps:  20\n",
      "episode: 243, sum:2061.875, avg: 103.094, closest:  0.034, final x, y, z:[ -0.000,   0.000,  10.034], steps:  20\n",
      "episode: 244, sum:1999.971, avg:  99.999, closest:  0.034, final x, y, z:[ -0.005,  -0.000,  10.034], steps:  20\n",
      "episode: 245, sum:2016.741, avg: 100.837, closest:  0.034, final x, y, z:[  0.001,  -0.000,  10.034], steps:  20\n",
      "episode: 246, sum:2051.701, avg: 102.585, closest:  0.034, final x, y, z:[  0.000,  -0.000,  10.034], steps:  20\n",
      "episode: 247, sum:2161.528, avg: 108.076, closest:  0.033, final x, y, z:[ -0.000,  -0.000,  10.033], steps:  20\n",
      "episode: 248, sum:2010.009, avg: 100.500, closest:  0.034, final x, y, z:[ -0.003,   0.000,  10.034], steps:  20\n",
      "episode: 249, sum:2097.353, avg: 104.868, closest:  0.033, final x, y, z:[ -0.001,  -0.000,  10.033], steps:  20\n",
      "episode: 250, sum:1941.525, avg:  97.076, closest:  0.035, final x, y, z:[ -0.002,  -0.000,  10.035], steps:  20\n",
      "episode: 251, sum:1990.484, avg:  99.524, closest:  0.034, final x, y, z:[  0.002,   0.000,  10.034], steps:  20\n",
      "episode: 252, sum:2003.352, avg: 100.168, closest:  0.034, final x, y, z:[  0.004,   0.000,  10.034], steps:  20\n",
      "episode: 253, sum:2090.818, avg: 104.541, closest:  0.033, final x, y, z:[ -0.000,   0.000,  10.033], steps:  20\n",
      "episode: 254, sum:1950.672, avg:  97.534, closest:  0.035, final x, y, z:[  0.001,  -0.000,  10.035], steps:  20\n",
      "episode: 255, sum:2137.056, avg: 106.853, closest:  0.033, final x, y, z:[ -0.001,   0.000,  10.033], steps:  20\n",
      "episode: 256, sum:2136.568, avg: 106.828, closest:  0.033, final x, y, z:[ -0.001,  -0.000,  10.033], steps:  20\n",
      "episode: 257, sum:2066.074, avg: 103.304, closest:  0.033, final x, y, z:[  0.000,   0.000,  10.033], steps:  20\n",
      "episode: 258, sum:2035.831, avg: 101.792, closest:  0.034, final x, y, z:[  0.001,   0.000,  10.034], steps:  20\n",
      "episode: 259, sum:1955.153, avg:  97.758, closest:  0.035, final x, y, z:[  0.001,  -0.000,  10.035], steps:  20\n",
      "episode: 260, sum:1975.650, avg:  98.782, closest:  0.034, final x, y, z:[  0.001,   0.000,  10.034], steps:  20\n",
      "episode: 261, sum:2045.823, avg: 102.291, closest:  0.034, final x, y, z:[ -0.002,  -0.000,  10.034], steps:  20\n",
      "episode: 262, sum:2059.857, avg: 102.993, closest:  0.034, final x, y, z:[ -0.000,   0.000,  10.034], steps:  20\n",
      "episode: 263, sum:2089.130, avg: 104.456, closest:  0.033, final x, y, z:[  0.003,  -0.000,  10.033], steps:  20\n",
      "episode: 264, sum:2105.255, avg: 105.263, closest:  0.033, final x, y, z:[ -0.000,   0.000,  10.033], steps:  20\n",
      "episode: 265, sum:2063.436, avg: 103.172, closest:  0.034, final x, y, z:[ -0.000,  -0.000,  10.034], steps:  20\n",
      "episode: 266, sum:2052.661, avg: 102.633, closest:  0.034, final x, y, z:[  0.004,  -0.000,  10.033], steps:  20\n",
      "episode: 267, sum:1985.771, avg:  99.289, closest:  0.034, final x, y, z:[ -0.000,  -0.000,  10.034], steps:  20\n",
      "episode: 268, sum:2011.235, avg: 100.562, closest:  0.034, final x, y, z:[  0.000,  -0.000,  10.034], steps:  20\n",
      "episode: 269, sum:2002.365, avg: 100.118, closest:  0.034, final x, y, z:[ -0.000,   0.000,  10.034], steps:  20\n",
      "episode: 270, sum:1977.862, avg:  98.893, closest:  0.034, final x, y, z:[ -0.000,  -0.000,  10.034], steps:  20\n",
      "episode: 271, sum:2072.005, avg: 103.600, closest:  0.033, final x, y, z:[  0.003,  -0.000,  10.033], steps:  20\n",
      "episode: 272, sum:2057.462, avg: 102.873, closest:  0.034, final x, y, z:[  0.000,  -0.000,  10.034], steps:  20\n",
      "episode: 273, sum:2026.751, avg: 101.338, closest:  0.034, final x, y, z:[ -0.003,  -0.000,  10.034], steps:  20\n",
      "episode: 274, sum:1963.421, avg:  98.171, closest:  0.035, final x, y, z:[ -0.001,  -0.000,  10.035], steps:  20\n",
      "episode: 275, sum:1987.243, avg:  99.362, closest:  0.034, final x, y, z:[  0.003,  -0.000,  10.034], steps:  20\n",
      "episode: 276, sum:2096.155, avg: 104.808, closest:  0.033, final x, y, z:[  0.000,   0.000,  10.033], steps:  20\n",
      "episode: 277, sum:2063.341, avg: 103.167, closest:  0.034, final x, y, z:[  0.003,  -0.000,  10.033], steps:  20\n",
      "episode: 278, sum:2040.444, avg: 102.022, closest:  0.034, final x, y, z:[ -0.004,   0.000,  10.033], steps:  20\n",
      "episode: 279, sum:2031.670, avg: 101.584, closest:  0.034, final x, y, z:[ -0.002,   0.000,  10.034], steps:  20\n",
      "episode: 280, sum:2061.345, avg: 103.067, closest:  0.034, final x, y, z:[  0.001,  -0.000,  10.034], steps:  20\n",
      "episode: 281, sum:2020.084, avg: 101.004, closest:  0.034, final x, y, z:[ -0.002,  -0.000,  10.034], steps:  20\n",
      "episode: 282, sum:2050.179, avg: 102.509, closest:  0.034, final x, y, z:[  0.000,   0.000,  10.034], steps:  20\n",
      "episode: 283, sum:2063.569, avg: 103.178, closest:  0.034, final x, y, z:[  0.001,   0.000,  10.034], steps:  20\n",
      "episode: 284, sum:2025.007, avg: 101.250, closest:  0.034, final x, y, z:[ -0.000,  -0.000,  10.034], steps:  20\n",
      "episode: 285, sum:2008.602, avg: 100.430, closest:  0.034, final x, y, z:[ -0.002,   0.000,  10.034], steps:  20\n",
      "episode: 286, sum:2065.508, avg: 103.275, closest:  0.033, final x, y, z:[  0.001,   0.000,  10.033], steps:  20\n",
      "episode: 287, sum:1989.550, avg:  99.478, closest:  0.034, final x, y, z:[  0.003,  -0.000,  10.034], steps:  20\n",
      "episode: 288, sum:2042.310, avg: 102.115, closest:  0.034, final x, y, z:[  0.000,  -0.000,  10.034], steps:  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 289, sum:1913.127, avg:  95.656, closest:  0.035, final x, y, z:[  0.001,   0.000,  10.035], steps:  20\n",
      "episode: 290, sum:2050.389, avg: 102.519, closest:  0.034, final x, y, z:[ -0.001,   0.000,  10.034], steps:  20\n",
      "episode: 291, sum:1976.278, avg:  98.814, closest:  0.034, final x, y, z:[ -0.002,  -0.000,  10.034], steps:  20\n",
      "episode: 292, sum:-1843.826, avg: -16.463, closest:  0.244, final x, y, z:[ -5.636,   1.694,   0.000], steps: 112\n",
      "episode: 293, sum:-978.814, avg: -13.595, closest:  0.998, final x, y, z:[  0.000,   0.481,   0.000], steps:  72\n",
      "episode: 294, sum:-1978.391, avg: -26.735, closest:  0.998, final x, y, z:[  0.000,   0.786,   0.000], steps:  74\n",
      "episode: 295, sum:-979.790, avg: -13.608, closest:  0.999, final x, y, z:[  0.000,   0.771,   0.000], steps:  72\n",
      "episode: 296, sum:-980.058, avg: -14.001, closest:  0.998, final x, y, z:[ -0.000,   0.575,   0.000], steps:  70\n",
      "episode: 297, sum:-977.797, avg: -13.037, closest:  0.998, final x, y, z:[ -0.000,   1.104,   0.000], steps:  75\n",
      "episode: 298, sum:-978.771, avg: -13.594, closest:  0.998, final x, y, z:[  0.000,   0.536,   0.000], steps:  72\n",
      "episode: 299, sum:-978.817, avg: -13.595, closest:  0.998, final x, y, z:[  0.000,   0.551,   0.000], steps:  72\n",
      "episode: 300, sum:-978.814, avg: -13.595, closest:  0.998, final x, y, z:[  0.000,   0.550,   0.000], steps:  72\n",
      "episode: 301, sum:-978.750, avg: -13.594, closest:  0.998, final x, y, z:[ -0.000,   0.525,   0.000], steps:  72\n",
      "episode: 302, sum:-978.808, avg: -13.595, closest:  0.998, final x, y, z:[ -0.000,   0.549,   0.000], steps:  72\n",
      "episode: 303, sum:-978.789, avg: -13.594, closest:  0.998, final x, y, z:[  0.000,   0.546,   0.000], steps:  72\n",
      "episode: 304, sum:-978.772, avg: -13.594, closest:  0.998, final x, y, z:[ -0.000,   0.534,   0.000], steps:  72\n",
      "episode: 305, sum:-978.760, avg: -13.594, closest:  0.998, final x, y, z:[  0.000,   0.533,   0.000], steps:  72\n",
      "episode: 306, sum:-978.753, avg: -13.594, closest:  0.998, final x, y, z:[ -0.000,   0.534,   0.000], steps:  72\n",
      "episode: 307, sum:-978.750, avg: -13.594, closest:  0.998, final x, y, z:[  0.000,   0.530,   0.000], steps:  72\n",
      "episode: 308, sum:-1978.824, avg: -27.107, closest:  0.998, final x, y, z:[ -0.722,   0.443,   0.000], steps:  73\n",
      "episode: 309, sum:-1929.437, avg: -20.526, closest:  0.599, final x, y, z:[ -6.306,  -5.426,   0.000], steps:  94\n",
      "episode: 310, sum:-968.469, avg: -10.414, closest:  0.881, final x, y, z:[ -7.555, -13.646,   0.000], steps:  93\n",
      "episode: 311, sum:-987.905, avg: -17.962, closest:  0.998, final x, y, z:[ -9.613,   0.037,   0.000], steps:  55\n",
      "episode: 312, sum:-987.998, avg: -17.964, closest:  0.998, final x, y, z:[ -9.538,   0.617,   0.000], steps:  55\n",
      "episode: 313, sum:-980.270, avg: -16.338, closest:  0.937, final x, y, z:[ -6.860,  -2.711,   0.000], steps:  60\n",
      "episode: 314, sum:-983.703, avg: -15.866, closest:  0.992, final x, y, z:[-10.797,  -4.888,   0.000], steps:  62\n",
      "episode: 315, sum:-979.649, avg: -16.890, closest:  0.924, final x, y, z:[ -5.538,   1.643,   0.000], steps:  58\n",
      "episode: 316, sum:-983.009, avg: -12.443, closest:  0.992, final x, y, z:[-11.666,  -5.752,   0.000], steps:  79\n",
      "episode: 317, sum:-973.141, avg: -11.585, closest:  0.895, final x, y, z:[ 10.138,   1.516,   0.000], steps:  84\n",
      "episode: 318, sum:-974.149, avg: -11.880, closest:  0.841, final x, y, z:[-18.596,   1.742,   0.000], steps:  82\n",
      "episode: 319, sum:-973.442, avg: -12.808, closest:  0.911, final x, y, z:[ -5.228,   0.301,   0.000], steps:  76\n",
      "episode: 320, sum:-1975.919, avg: -16.064, closest:  0.974, final x, y, z:[ 10.448,  -2.504,   0.000], steps: 123\n",
      "episode: 321, sum:-1954.865, avg: -23.553, closest:  0.716, final x, y, z:[  1.677,   1.203,   0.000], steps:  83\n",
      "episode: 322, sum:-1959.149, avg: -23.892, closest:  0.751, final x, y, z:[ -1.175,   1.532,   0.000], steps:  82\n",
      "episode: 323, sum:-1960.304, avg: -23.906, closest:  0.761, final x, y, z:[  1.410,   1.643,   0.000], steps:  82\n",
      "episode: 324, sum:-1961.292, avg: -23.918, closest:  0.773, final x, y, z:[  0.111,   1.786,   0.000], steps:  82\n",
      "episode: 325, sum:-961.373, avg: -11.869, closest:  0.773, final x, y, z:[  0.902,   1.754,   0.000], steps:  81\n",
      "episode: 326, sum:-961.736, avg: -11.873, closest:  0.777, final x, y, z:[  0.215,   1.802,   0.000], steps:  81\n",
      "episode: 327, sum:-960.490, avg: -11.713, closest:  0.763, final x, y, z:[  2.148,   1.548,   0.000], steps:  82\n",
      "episode: 328, sum:-962.216, avg: -11.879, closest:  0.781, final x, y, z:[ -1.352,   1.811,   0.000], steps:  81\n",
      "episode: 329, sum:-961.604, avg: -11.872, closest:  0.774, final x, y, z:[  1.722,   1.769,   0.000], steps:  81\n",
      "episode: 330, sum:-962.182, avg: -11.879, closest:  0.782, final x, y, z:[ -0.108,   1.821,   0.000], steps:  81\n",
      "episode: 331, sum:-962.310, avg: -11.880, closest:  0.782, final x, y, z:[ -0.372,   1.855,   0.000], steps:  81\n",
      "episode: 332, sum:-962.159, avg: -11.879, closest:  0.780, final x, y, z:[ -0.315,   1.810,   0.000], steps:  81\n",
      "episode: 333, sum:-961.781, avg: -11.874, closest:  0.777, final x, y, z:[  1.061,   1.799,   0.000], steps:  81\n",
      "episode: 334, sum:-962.312, avg: -11.880, closest:  0.782, final x, y, z:[  0.278,   1.841,   0.000], steps:  81\n",
      "episode: 335, sum:-962.007, avg: -11.877, closest:  0.778, final x, y, z:[ -0.280,   1.809,   0.000], steps:  81\n",
      "episode: 336, sum:-962.846, avg: -11.887, closest:  0.788, final x, y, z:[ -1.098,   1.892,   0.000], steps:  81\n",
      "episode: 337, sum:-961.607, avg: -11.872, closest:  0.774, final x, y, z:[  0.257,   1.769,   0.000], steps:  81\n",
      "episode: 338, sum:-962.111, avg: -11.878, closest:  0.780, final x, y, z:[  0.321,   1.813,   0.000], steps:  81\n",
      "episode: 339, sum:-961.876, avg: -11.875, closest:  0.777, final x, y, z:[  1.044,   1.798,   0.000], steps:  81\n",
      "episode: 340, sum:-962.507, avg: -11.883, closest:  0.786, final x, y, z:[ -0.525,   1.866,   0.000], steps:  81\n",
      "episode: 341, sum:-962.168, avg: -11.879, closest:  0.781, final x, y, z:[ -0.625,   1.831,   0.000], steps:  81\n",
      "episode: 342, sum:-971.339, avg: -11.846, closest:  0.798, final x, y, z:[-13.725,   1.659,   0.000], steps:  82\n",
      "episode: 343, sum:-984.016, avg: -14.687, closest:  0.966, final x, y, z:[ -4.229,   1.271,   0.000], steps:  67\n",
      "episode: 344, sum:-963.088, avg: -11.890, closest:  0.791, final x, y, z:[  0.818,   1.919,   0.000], steps:  81\n",
      "episode: 345, sum:-962.678, avg: -11.885, closest:  0.787, final x, y, z:[  0.496,   1.882,   0.000], steps:  81\n",
      "episode: 346, sum:-962.458, avg: -11.882, closest:  0.785, final x, y, z:[ -0.236,   1.867,   0.000], steps:  81\n",
      "episode: 347, sum:-962.868, avg: -11.887, closest:  0.789, final x, y, z:[  0.682,   1.904,   0.000], steps:  81\n",
      "episode: 348, sum:-962.407, avg: -11.882, closest:  0.783, final x, y, z:[ -1.079,   1.851,   0.000], steps:  81\n",
      "episode: 349, sum:-962.637, avg: -11.884, closest:  0.787, final x, y, z:[ -1.244,   1.877,   0.000], steps:  81\n",
      "episode: 350, sum:-962.307, avg: -11.880, closest:  0.783, final x, y, z:[  0.071,   1.837,   0.000], steps:  81\n",
      "episode: 351, sum:-983.457, avg: -12.940, closest:  0.969, final x, y, z:[  3.627,   0.953,   0.000], steps:  76\n",
      "episode: 352, sum:-1980.474, avg: -23.861, closest:  0.983, final x, y, z:[  4.500,   1.123,   0.000], steps:  83\n",
      "episode: 353, sum:-1979.669, avg: -26.752, closest:  0.944, final x, y, z:[ -4.941,   2.571,   0.000], steps:  74\n",
      "episode: 354, sum:-1985.087, avg: -24.507, closest:  0.996, final x, y, z:[-14.275,   2.525,   0.000], steps:  81\n",
      "episode: 355, sum:-976.016, avg: -13.014, closest:  0.907, final x, y, z:[ -9.416,  -1.995,   0.000], steps:  75\n",
      "episode: 356, sum:-982.445, avg: -12.595, closest:  0.956, final x, y, z:[  1.460,  -2.203,   0.000], steps:  78\n",
      "episode: 357, sum:-1977.614, avg: -19.200, closest:  0.902, final x, y, z:[-11.266,  -3.890,   0.000], steps: 103\n",
      "episode: 358, sum:-944.148, avg:  -7.263, closest:  0.456, final x, y, z:[-40.567,   0.248,   0.000], steps: 130\n",
      "episode: 359, sum:-948.591, avg: -11.857, closest:  0.604, final x, y, z:[-10.897,  -2.122,   0.000], steps:  80\n",
      "episode: 360, sum:6057.272, avg: 378.579, closest:  0.018, final x, y, z:[ -0.001,  -0.018,  10.005], steps:  16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 361, sum:-573.125, avg:  -3.872, closest:  0.072, final x, y, z:[ 13.196,   3.388,   0.000], steps: 148\n",
      "episode: 362, sum:1360.352, avg:  85.022, closest:  0.039, final x, y, z:[ -0.000,  -0.013,   9.963], steps:  16\n",
      "episode: 363, sum:1372.417, avg:  91.494, closest:  0.039, final x, y, z:[  0.000,  -0.005,   9.961], steps:  15\n",
      "episode: 364, sum:-980.269, avg: -13.807, closest:  0.970, final x, y, z:[  3.275,   2.006,   0.000], steps:  71\n",
      "episode: 365, sum:-1986.460, avg: -25.798, closest:  0.982, final x, y, z:[-26.519,  -0.392,   0.000], steps:  77\n",
      "episode: 366, sum:-1978.024, avg: -20.604, closest:  0.786, final x, y, z:[-27.713,  -6.920,   0.000], steps:  96\n",
      "episode: 367, sum:3107.963, avg: 194.248, closest:  0.026, final x, y, z:[ -0.000,   0.004,  10.026], steps:  16\n",
      "episode: 368, sum:1159.422, avg:  72.464, closest:  0.044, final x, y, z:[  0.000,   0.002,  10.044], steps:  16\n",
      "episode: 369, sum:-629.395, avg:  -3.313, closest:  0.074, final x, y, z:[ -5.367,   1.115,   0.000], steps: 190\n",
      "episode: 370, sum:-1940.914, avg: -23.106, closest:  0.560, final x, y, z:[ -1.618,   5.075,   0.000], steps:  84\n",
      "episode: 371, sum:-685.329, avg:  -5.039, closest:  0.095, final x, y, z:[  6.189,   2.658,   0.000], steps: 136\n",
      "episode: 372, sum:-950.022, avg:  -9.500, closest:  0.680, final x, y, z:[  7.321,  -6.323,   0.000], steps: 100\n",
      "episode: 373, sum:2502.180, avg: 125.109, closest:  0.030, final x, y, z:[ -0.000,   0.006,  10.029], steps:  20\n",
      "episode: 374, sum:-669.090, avg:  -6.434, closest:  0.099, final x, y, z:[ -3.352,   3.529,   0.000], steps: 104\n",
      "episode: 375, sum:2343.341, avg: 117.167, closest:  0.031, final x, y, z:[  0.000,   0.006,  10.031], steps:  20\n",
      "episode: 376, sum:2186.653, avg: 109.333, closest:  0.032, final x, y, z:[ -0.000,   0.007,  10.032], steps:  20\n",
      "episode: 377, sum:-519.899, avg:  -3.636, closest:  0.065, final x, y, z:[  4.697,   3.797,   0.000], steps: 143\n",
      "episode: 378, sum:-1915.144, avg: -15.570, closest:  0.275, final x, y, z:[  1.677, -15.837,   0.000], steps: 123\n",
      "episode: 379, sum: 242.666, avg:   2.789, closest:  0.051, final x, y, z:[-12.554,  -5.245,   0.000], steps:  87\n",
      "episode: 380, sum:-1933.053, avg: -18.066, closest:  0.419, final x, y, z:[  3.313,  -0.309,   0.000], steps: 107\n",
      "episode: 381, sum:-850.362, avg:  -5.451, closest:  0.147, final x, y, z:[-10.122, -24.676,   0.000], steps: 156\n",
      "episode: 382, sum:-986.179, avg: -15.654, closest:  0.985, final x, y, z:[  1.301,   5.773,   0.000], steps:  63\n",
      "episode: 383, sum:1442.739, avg:  75.934, closest:  0.043, final x, y, z:[ -0.000,   0.009,  10.042], steps:  19\n",
      "episode: 384, sum:-874.697, avg:  -6.338, closest:  0.211, final x, y, z:[ -6.945, -14.460,   0.000], steps: 138\n",
      "episode: 385, sum:1791.264, avg:  89.563, closest:  0.036, final x, y, z:[ -0.000,   0.027,  10.023], steps:  20\n",
      "episode: 386, sum:-924.977, avg:  -8.114, closest:  0.449, final x, y, z:[ 35.200,   3.346,   0.000], steps: 114\n",
      "episode: 387, sum:-963.486, avg:  -9.176, closest:  0.682, final x, y, z:[ 16.659,  -3.628,   0.000], steps: 105\n",
      "episode: 388, sum:-982.608, avg: -13.840, closest:  0.952, final x, y, z:[ 15.735,   6.389,   0.000], steps:  71\n",
      "episode: 389, sum:-1983.652, avg: -27.551, closest:  0.973, final x, y, z:[ -3.335,   8.648,   0.000], steps:  72\n",
      "episode: 390, sum:-985.987, avg: -13.507, closest:  0.999, final x, y, z:[  4.876,   4.073,   0.000], steps:  73\n",
      "episode: 391, sum:-987.293, avg: -13.525, closest:  0.999, final x, y, z:[ -1.301,  -8.930,   0.000], steps:  73\n",
      "episode: 392, sum:-984.760, avg: -11.723, closest:  0.990, final x, y, z:[-24.942,   8.251,   0.000], steps:  84\n",
      "episode: 393, sum:-943.086, avg:  -8.061, closest:  0.630, final x, y, z:[  8.673,   4.415,   0.000], steps: 117\n",
      "episode: 394, sum:-1971.166, avg: -24.640, closest:  0.965, final x, y, z:[ 14.544,   1.221,   0.000], steps:  80\n",
      "episode: 395, sum:-852.859, avg: -10.661, closest:  0.321, final x, y, z:[ -3.087,  -1.206,   0.000], steps:  80\n",
      "episode: 396, sum:-1470.107, avg: -13.010, closest:  0.083, final x, y, z:[ -3.193,   6.885,   0.000], steps: 113\n",
      "episode: 397, sum:-1957.251, avg: -19.379, closest:  0.666, final x, y, z:[  6.010,   5.437,   0.000], steps: 101\n",
      "episode: 398, sum:-1949.844, avg: -15.115, closest:  0.545, final x, y, z:[-40.161,   5.635,   0.000], steps: 129\n",
      "episode: 399, sum:-1958.349, avg: -21.286, closest:  0.616, final x, y, z:[  0.634,   1.144,   0.000], steps:  92\n",
      "episode: 400, sum:-939.656, avg: -10.214, closest:  0.537, final x, y, z:[ -5.347,   2.624,   0.000], steps:  92\n",
      "episode: 401, sum:-979.452, avg: -10.883, closest:  0.991, final x, y, z:[ -2.579,   0.878,   0.000], steps:  90\n",
      "episode: 402, sum:-976.091, avg: -10.384, closest:  0.906, final x, y, z:[ -5.031,  -5.440,   0.000], steps:  94\n",
      "episode: 403, sum:-920.742, avg:  -9.207, closest:  0.426, final x, y, z:[-16.193,  -6.871,   0.000], steps: 100\n",
      "episode: 404, sum:2279.434, avg: 113.972, closest:  0.031, final x, y, z:[ -0.000,   0.011,  10.030], steps:  20\n",
      "episode: 405, sum:-1949.064, avg: -20.735, closest:  0.608, final x, y, z:[  6.275,   0.815,   0.000], steps:  94\n",
      "episode: 406, sum:-983.999, avg: -14.057, closest:  0.996, final x, y, z:[ -6.286,  -1.258,   0.000], steps:  70\n",
      "episode: 407, sum:-977.433, avg:  -8.967, closest:  0.917, final x, y, z:[-18.283,   4.761,   0.000], steps: 109\n",
      "episode: 408, sum:-989.617, avg: -21.991, closest:  0.999, final x, y, z:[ -0.265,  -0.893,   0.000], steps:  45\n",
      "episode: 409, sum:-1950.774, avg: -21.437, closest:  0.561, final x, y, z:[ -3.446,   7.465,   0.000], steps:  91\n",
      "episode: 410, sum:-989.366, avg: -20.612, closest:  0.999, final x, y, z:[ -0.333,  -0.556,   0.000], steps:  48\n",
      "episode: 411, sum:-980.468, avg: -13.073, closest:  1.000, final x, y, z:[ -7.257,  -0.869,   0.000], steps:  75\n",
      "episode: 412, sum:-1983.694, avg: -21.330, closest:  0.996, final x, y, z:[ -9.897,  -0.562,   0.000], steps:  93\n",
      "episode: 413, sum:-963.351, avg:  -7.526, closest:  0.755, final x, y, z:[ -8.371,  -0.290,   0.000], steps: 128\n",
      "episode: 414, sum:-926.927, avg:  -8.663, closest:  0.412, final x, y, z:[ -5.068,  -1.101,   0.000], steps: 107\n",
      "episode: 415, sum:-1622.121, avg: -16.552, closest:  0.139, final x, y, z:[ -2.330,  -2.972,   0.000], steps:  98\n",
      "episode: 416, sum:-982.188, avg: -15.842, closest:  1.000, final x, y, z:[ -5.422,   2.067,   0.000], steps:  62\n",
      "episode: 417, sum:-973.396, avg: -10.816, closest:  0.845, final x, y, z:[-15.997,   9.336,   0.000], steps:  90\n",
      "episode: 418, sum:-972.277, avg: -12.627, closest:  0.930, final x, y, z:[ -3.399,  -0.244,   0.000], steps:  77\n",
      "episode: 419, sum:-865.266, avg:  -7.795, closest:  0.240, final x, y, z:[  8.298,  12.166,   0.000], steps: 111\n",
      "episode: 420, sum:-971.817, avg: -11.170, closest:  0.845, final x, y, z:[ -0.309,  -9.182,   0.000], steps:  87\n",
      "episode: 421, sum:  28.318, avg:   0.113, closest:  0.845, final x, y, z:[ 28.505,  68.970,   6.246], steps: 251\n",
      "episode: 422, sum:-980.010, avg: -13.425, closest:  0.965, final x, y, z:[  4.697,   1.644,   0.000], steps:  73\n",
      "episode: 423, sum:-987.870, avg: -18.998, closest:  0.999, final x, y, z:[ -4.374,   0.502,   0.000], steps:  52\n",
      "episode: 424, sum:-1985.160, avg: -32.019, closest:  0.999, final x, y, z:[ -9.885,   0.841,   0.000], steps:  62\n",
      "episode: 425, sum:-959.890, avg:  -9.504, closest:  1.000, final x, y, z:[ -0.754,  -3.000,   0.000], steps: 101\n",
      "episode: 426, sum:-985.755, avg: -14.936, closest:  0.999, final x, y, z:[-12.450,  -0.054,   0.000], steps:  66\n",
      "episode: 427, sum:-787.772, avg:  -6.405, closest:  0.147, final x, y, z:[ -2.252,   7.991,   0.000], steps: 123\n",
      "episode: 428, sum:-984.702, avg: -13.869, closest:  0.999, final x, y, z:[ 14.230,   0.306,   0.000], steps:  71\n",
      "episode: 429, sum:-1976.823, avg: -23.817, closest:  0.997, final x, y, z:[ -1.063,  -5.913,   0.000], steps:  83\n",
      "episode: 430, sum:-941.219, avg:  -9.908, closest:  0.650, final x, y, z:[ -8.767,  -2.292,   0.000], steps:  95\n",
      "episode: 431, sum:-982.339, avg: -13.836, closest:  0.999, final x, y, z:[ -0.022,  -2.127,   0.000], steps:  71\n",
      "episode: 432, sum:-976.228, avg: -13.946, closest:  0.974, final x, y, z:[ -2.613,   0.200,   0.000], steps:  70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 433, sum:-1724.021, avg: -15.257, closest:  0.142, final x, y, z:[-21.866,   2.024,   0.000], steps: 113\n",
      "episode: 434, sum:-1983.749, avg: -27.175, closest:  0.996, final x, y, z:[-12.136,   0.476,   0.000], steps:  73\n",
      "episode: 435, sum:-980.541, avg: -14.008, closest:  0.994, final x, y, z:[ -0.856,  -1.043,   0.000], steps:  70\n",
      "episode: 436, sum:-1965.063, avg: -13.742, closest:  0.770, final x, y, z:[ -2.138,  -5.729,   0.000], steps: 143\n",
      "episode: 437, sum:-971.719, avg: -11.432, closest:  0.926, final x, y, z:[ -0.000,  -4.185,   0.000], steps:  85\n",
      "episode: 438, sum:-950.139, avg:  -9.049, closest:  0.552, final x, y, z:[  0.015, -10.357,   0.000], steps: 105\n",
      "episode: 439, sum:4547.367, avg: 227.368, closest:  0.021, final x, y, z:[  0.000,  -0.020,   9.992], steps:  20\n",
      "episode: 440, sum:-973.582, avg: -11.730, closest:  0.957, final x, y, z:[  0.273,   1.998,   0.000], steps:  83\n",
      "episode: 441, sum:26493.703, avg:1324.685, closest:  0.009, final x, y, z:[ -0.000,   0.001,  10.009], steps:  20\n",
      "episode: 442, sum:2436.667, avg: 121.833, closest:  0.030, final x, y, z:[ -0.000,  -0.023,  10.019], steps:  20\n",
      "episode: 443, sum:2436.207, avg: 121.810, closest:  0.030, final x, y, z:[ -0.000,  -0.027,  10.013], steps:  20\n",
      "episode: 444, sum:-1981.954, avg: -25.740, closest:  0.999, final x, y, z:[-18.885,   0.578,   0.000], steps:  77\n",
      "episode: 445, sum:2205.624, avg: 110.281, closest:  0.032, final x, y, z:[ -0.000,   0.009,  10.031], steps:  20\n",
      "episode: 446, sum:2140.345, avg: 107.017, closest:  0.033, final x, y, z:[  0.000,   0.000,  10.033], steps:  20\n",
      "episode: 447, sum:-973.596, avg: -12.482, closest:  0.957, final x, y, z:[ -8.367,   1.033,   0.000], steps:  78\n",
      "episode: 448, sum:3198.854, avg: 159.943, closest:  0.026, final x, y, z:[  0.000,  -0.006,  10.025], steps:  20\n",
      "episode: 449, sum:2181.320, avg: 109.066, closest:  0.032, final x, y, z:[  0.000,   0.006,  10.032], steps:  20\n",
      "episode: 450, sum:2096.124, avg: 104.806, closest:  0.033, final x, y, z:[  0.000,   0.013,  10.030], steps:  20\n",
      "episode: 451, sum:-890.183, avg: -10.473, closest:  0.435, final x, y, z:[  3.359,  -0.562,   0.000], steps:  85\n",
      "episode: 452, sum:2131.844, avg: 106.592, closest:  0.033, final x, y, z:[ -0.000,  -0.014,  10.029], steps:  20\n",
      "episode: 453, sum:-754.082, avg:  -6.391, closest:  0.143, final x, y, z:[ -2.270,  -0.781,   0.000], steps: 118\n",
      "episode: 454, sum:2170.113, avg: 108.506, closest:  0.033, final x, y, z:[  0.000,   0.002,  10.032], steps:  20\n",
      "episode: 455, sum:2018.117, avg: 100.906, closest:  0.034, final x, y, z:[ -0.000,   0.002,  10.034], steps:  20\n",
      "episode: 456, sum:2241.191, avg: 112.060, closest:  0.032, final x, y, z:[ -0.000,   0.003,  10.032], steps:  20\n",
      "episode: 457, sum:2034.991, avg: 101.750, closest:  0.034, final x, y, z:[ -0.000,   0.004,  10.034], steps:  20\n",
      "episode: 458, sum:6870.236, avg: 327.154, closest:  0.017, final x, y, z:[ -0.003,   0.014,   9.990], steps:  21\n",
      "episode: 459, sum:-1970.604, avg: -23.742, closest:  0.913, final x, y, z:[  3.621,  -1.993,   0.000], steps:  83\n",
      "episode: 460, sum:-983.743, avg: -19.289, closest:  0.928, final x, y, z:[ -1.788,  -0.729,   0.000], steps:  51\n",
      "episode: 461, sum:1957.461, avg:  97.873, closest:  0.035, final x, y, z:[ -0.000,   0.004,  10.034], steps:  20\n",
      "episode: 462, sum:2802.700, avg: 140.135, closest:  0.028, final x, y, z:[  0.000,  -0.002,  10.028], steps:  20\n",
      "episode: 463, sum:1956.192, avg:  97.810, closest:  0.035, final x, y, z:[ -0.000,   0.004,  10.034], steps:  20\n",
      "episode: 464, sum:2990.361, avg: 149.518, closest:  0.027, final x, y, z:[  0.000,  -0.004,  10.027], steps:  20\n",
      "episode: 465, sum:2194.787, avg: 109.739, closest:  0.032, final x, y, z:[ -0.000,  -0.007,  10.031], steps:  20\n",
      "episode: 466, sum:2086.933, avg: 104.347, closest:  0.033, final x, y, z:[ -0.000,  -0.003,  10.033], steps:  20\n",
      "episode: 467, sum:2187.634, avg: 109.382, closest:  0.032, final x, y, z:[  0.000,   0.003,  10.032], steps:  20\n",
      "episode: 468, sum:1959.259, avg:  97.963, closest:  0.035, final x, y, z:[ -0.000,  -0.002,  10.035], steps:  20\n",
      "episode: 469, sum:2001.119, avg: 100.056, closest:  0.034, final x, y, z:[ -0.000,   0.002,  10.034], steps:  20\n",
      "episode: 470, sum:2102.691, avg: 105.135, closest:  0.033, final x, y, z:[ -0.000,   0.001,  10.033], steps:  20\n",
      "episode: 471, sum:2260.815, avg: 113.041, closest:  0.032, final x, y, z:[  0.000,  -0.008,  10.031], steps:  20\n",
      "episode: 472, sum:1982.284, avg:  99.114, closest:  0.034, final x, y, z:[ -0.000,  -0.001,  10.034], steps:  20\n",
      "episode: 473, sum:1993.763, avg:  99.688, closest:  0.034, final x, y, z:[ -0.000,   0.003,  10.034], steps:  20\n",
      "episode: 474, sum:2052.977, avg: 102.649, closest:  0.034, final x, y, z:[ -0.000,   0.002,  10.034], steps:  20\n",
      "episode: 475, sum:2051.448, avg: 102.572, closest:  0.034, final x, y, z:[ -0.000,  -0.004,  10.033], steps:  20\n",
      "episode: 476, sum:2062.618, avg: 103.131, closest:  0.034, final x, y, z:[  0.000,   0.002,  10.033], steps:  20\n",
      "episode: 477, sum:2037.248, avg: 101.862, closest:  0.034, final x, y, z:[ -0.001,  -0.002,  10.034], steps:  20\n",
      "episode: 478, sum:2371.846, avg: 118.592, closest:  0.031, final x, y, z:[  0.000,   0.019,  10.024], steps:  20\n",
      "episode: 479, sum: 398.987, avg:   1.590, closest:  0.088, final x, y, z:[ -5.561,  -4.244,  20.005], steps: 251\n",
      "episode: 480, sum:-983.400, avg: -16.955, closest:  0.992, final x, y, z:[ -6.929,  -4.667,   0.000], steps:  58\n",
      "episode: 481, sum:-975.557, avg: -14.346, closest:  0.978, final x, y, z:[  0.101,  -1.104,   0.000], steps:  68\n",
      "episode: 482, sum:2671.905, avg: 133.595, closest:  0.028, final x, y, z:[ -0.000,  -0.026,  10.011], steps:  20\n",
      "episode: 483, sum:-979.115, avg: -11.940, closest:  0.946, final x, y, z:[-22.790,  -2.064,   0.000], steps:  82\n",
      "episode: 484, sum:2776.317, avg: 138.816, closest:  0.028, final x, y, z:[  0.000,  -0.010,  10.026], steps:  20\n",
      "episode: 485, sum:2820.928, avg: 141.046, closest:  0.028, final x, y, z:[ -0.000,  -0.027,  10.007], steps:  20\n",
      "episode: 486, sum:2075.567, avg: 103.778, closest:  0.033, final x, y, z:[ -0.000,  -0.003,  10.033], steps:  20\n",
      "episode: 487, sum:2437.535, avg: 121.877, closest:  0.030, final x, y, z:[  0.000,  -0.003,  10.030], steps:  20\n",
      "episode: 488, sum:3256.805, avg: 162.840, closest:  0.026, final x, y, z:[  0.000,  -0.013,  10.022], steps:  20\n",
      "episode: 489, sum:2621.804, avg: 131.090, closest:  0.029, final x, y, z:[  0.000,  -0.014,  10.026], steps:  20\n",
      "episode: 490, sum:2039.191, avg: 101.960, closest:  0.033, final x, y, z:[ -0.000,  -0.022,  10.025], steps:  20\n",
      "episode: 491, sum:2276.814, avg: 113.841, closest:  0.031, final x, y, z:[  0.000,  -0.011,  10.029], steps:  20\n",
      "episode: 492, sum:6334.347, avg: 316.717, closest:  0.018, final x, y, z:[  0.000,   0.003,  10.018], steps:  20\n",
      "episode: 493, sum:2995.992, avg: 149.800, closest:  0.027, final x, y, z:[  0.000,  -0.014,  10.023], steps:  20\n",
      "episode: 494, sum:-581.601, avg:  -5.935, closest:  0.161, final x, y, z:[  0.877,   3.343,   0.000], steps:  98\n",
      "episode: 495, sum:-885.586, avg: -12.300, closest:  0.289, final x, y, z:[ -8.039,   2.253,   0.000], steps:  72\n",
      "episode: 496, sum:-1984.018, avg: -27.178, closest:  0.980, final x, y, z:[ -6.046,   8.234,   0.000], steps:  73\n",
      "episode: 497, sum:-1979.328, avg: -29.542, closest:  0.998, final x, y, z:[ -0.624,   1.834,   0.000], steps:  67\n",
      "episode: 498, sum:-1979.277, avg: -27.877, closest:  0.995, final x, y, z:[ -1.865,   1.925,   0.000], steps:  71\n",
      "episode: 499, sum:-980.325, avg:  -8.451, closest:  0.990, final x, y, z:[ -3.375,  16.580,   0.000], steps: 116\n",
      "episode: 500, sum:-1979.377, avg: -29.543, closest:  0.994, final x, y, z:[ -0.930,   1.255,   0.000], steps:  67"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "from agents.agent import DDPG\n",
    "from task import Task\n",
    "\n",
    "num_episodes = 500\n",
    "init_pose = np.array([0., 0., 9., 0., 0., 0.])\n",
    "target_pos = np.array([0., 0., 10.])\n",
    "task = Task(init_pose=init_pose, target_pos=target_pos)\n",
    "agent = DDPG(task)\n",
    "\n",
    "results = []\n",
    "\n",
    "for episode in range(1, num_episodes + 1):\n",
    "    episode_results = { 'time': [], 'reward': [], 'distance': [], 'x': [], 'y': [], 'z': [] }\n",
    "    state = agent.reset_episode()\n",
    "    best_reward = None\n",
    "    sum_reward = 0\n",
    "    avg_reward = 0\n",
    "    best_distance = None\n",
    "    steps = 0\n",
    "    \n",
    "    while True:\n",
    "        steps += 1\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, distance, done = task.step(action)\n",
    "        agent.step(action, reward, next_state, done)\n",
    "        \n",
    "        episode_results['time'].append(task.sim.time)\n",
    "        episode_results['reward'].append(reward)\n",
    "        episode_results['distance'].append(distance)\n",
    "        x, y, z = task.sim.pose[:3]\n",
    "        episode_results['x'].append(x)\n",
    "        episode_results['y'].append(y)\n",
    "        episode_results['z'].append(z)\n",
    "        best_reward = max(best_reward, reward) if best_reward is not None else reward\n",
    "        best_distance = min(best_distance, distance) if best_distance is not None else distance\n",
    "        if done:\n",
    "            break\n",
    "        state = next_state\n",
    "        \n",
    "    sum_reward = np.sum(episode_results['reward'])\n",
    "    avg_reward = np.average(episode_results['reward'])\n",
    "    \n",
    "    print(\"\\nepisode:{:4d}, sum:{:8.3f}, avg:{:8.3f}, closest:{:7.3f}, final x, y, z:[{:7.3f}, {:7.3f}, {:7.3f}], steps:{:4d}\".format(episode, sum_reward, avg_reward, best_distance, x, y, z, steps), end=\"\")\n",
    "    \n",
    "    results.append(episode_results)\n",
    "    sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Plot the Rewards\n",
    "\n",
    "Once you are satisfied with your performance, plot the episode rewards, either from a single run, or averaged over multiple runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11bdda358>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "for i in range(49, len(results), 50):\n",
    "    episode_results = results[i]\n",
    "    plt.plot(episode_results['time'], episode_results['reward'], label='episode {}'.format(i+1))\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12e2382e8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum_rewards = list(map(lambda x: np.sum(x['reward']), results))\n",
    "\n",
    "plt.plot(range(num_episodes), sum_rewards, label='sum')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "_ = plt.ylim()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13110bef0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "episode_num = 100\n",
    "episode_results = results[episode_num - 1]\n",
    "plt.plot(episode_results['time'], episode_results['distance'], label='distance')\n",
    "plt.plot(episode_results['time'], episode_results['x'], label='x')\n",
    "plt.plot(episode_results['time'], episode_results['y'], label='y')\n",
    "plt.plot(episode_results['time'], episode_results['z'], label='z')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Reflections\n",
    "\n",
    "**Question 1**: Describe the task that you specified in `task.py`.  How did you design the reward function?\n",
    "\n",
    "**Answer**:\n",
    "The task was very simple: get from [0, 0, 9] (stationary) to [0, 0, 10]. \n",
    "\n",
    "The design of the reward followed a lot of trial and error. I found the simplest reward had the most effect in guiding the agent to the target. I played with the following:\n",
    "\n",
    "1. a \"top hat\" function payoff for getting within a certain distance of the target \n",
    "2. a reward that grew as 1 / [distance from target ** 2], to act as a strong attractor to the target\n",
    "3. a time penalty, so that it wouldn't fall into a minima of staying up as long as possible but not actually reach the target\n",
    "4. a large step function penalty for coming within a certain distance of the ground, to discourage crashing (which it might start doing to minimise the time penalty)\n",
    "\n",
    "I assumed in the end that a complex reward function might be confusing gradient descent. So I combined 2 and 4 alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**: Discuss your agent briefly, using the following questions as a guide:\n",
    "\n",
    "- What learning algorithm(s) did you try? What worked best for you?\n",
    "- What was your final choice of hyperparameters (such as $\\alpha$, $\\gamma$, $\\epsilon$, etc.)?\n",
    "- What neural network architecture did you use (if any)? Specify layers, sizes, activation functions, etc.\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "I used the given DDPG solution. This combines (as you know ...) an actor mapping state to action, and a critic mapping (state, action) to Q value.\n",
    "\n",
    "The actor NN has layers:\n",
    "\n",
    "1. input layer (shape = state shape)\n",
    "2. 3 hidden dense layers (32, 64, 32, with all ReLU activations)\n",
    "3. sigmoid activation layer (shape = action shape)\n",
    "\n",
    "The critic NN has 2 pathways:\n",
    "\n",
    "1. state input layer + 2 x dense layers (32, 64, ReLU)\n",
    "2. action input layer + 2 x dense layers (32, 64, ReLU)\n",
    "\n",
    "which are then combined in a final dense layer with 1 unit.\n",
    "\n",
    "After tweaking the noise hyperparameters ($\\mu$, $\\theta$, $\\sigma$) and the learning hyperparameters ($\\gamma$, $\\tau$) many times, I found the original settings seemed to be a good enough balance between exploration and remembering good results.\n",
    "\n",
    "I did not change the neural networks as after trial and error I observed the largest effect seemed to come from altering the reward function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**: Using the episode rewards plot, discuss how the agent learned over time.\n",
    "\n",
    "- Was it an easy task to learn or hard?\n",
    "- Was there a gradual learning curve, or an aha moment?\n",
    "- How good was the final performance of the agent? (e.g. mean rewards over the last 10 episodes)\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "With the initial position much closer to the target (I originally tried to get it to launch from the ground) and with the final reward function, it would typically find the solution < 100 episodes. \n",
    "\n",
    "Possibly because I started the quadcopter so close to the target and marked done = True when within a certain distance, it would stick to a correct solution for a large number of subsequent episodes. There was no gradual learning curve.\n",
    "\n",
    "The final performance still seemed erratic, but that seemed to be because if it explored a little, it would often crash. But it seemed to be learning as it would return to hitting the target after shorter runs of crashed than at the start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**: Briefly summarize your experience working on this project. You can use the following prompts for ideas.\n",
    "\n",
    "- What was the hardest part of the project? (e.g. getting started, plotting, specifying the task, etc.)\n",
    "- Did you find anything interesting in how the quadcopter or your agent behaved?\n",
    "\n",
    "**Answer**: \n",
    "\n",
    "The 1st hardest thing was to figure out how to diagnose why it was not hitting its goal. The 2nd hardest was coming up with a theory as to why it was crashing all the time. There are so many variables to play with it can be hard even coming up with logging or visualisations to diagnose.\n",
    "\n",
    "The sensitivity to the reward function was surprising, when compared to some of the earlier mini-projects we walked through in this module. It may be easier to put the quadcopter in a \"training box\", where rather than crash / finish when hitting the limits, it would simply be prevented from proceeding. Perhaps then a simple time penalty at each step combined with a payoff for hitting the target would make it more straightforward to train - although early episodes may end up with huge numbers of steps."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "quadcop",
   "language": "python",
   "name": "quadcop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
